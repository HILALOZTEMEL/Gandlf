Görüntülenen çıkış son 5000 satıra kısaltıldı.
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 26.58it/s]
     Epoch Final   validation loss :  0.999014675989747
     Epoch Final   validation dice :  0.1515037752687931
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.36it/s]
     Epoch Final   testing loss :  0.9990359105874057
     Epoch Final   testing dice :  0.15240620614136036
Time taken for epoch :  0.8275751113891602  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:34<00:00, 18.82it/s]
     Epoch Final   Train loss :  0.9990546762573053
     Epoch Final   Train dice :  0.14864913131231847
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 26.62it/s]
     Epoch Final   validation loss :  0.999032387137413
     Epoch Final   validation dice :  0.14969973666593434
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.48it/s]
     Epoch Final   testing loss :  0.9990553799553297
     Epoch Final   testing dice :  0.1505303881061611
Time taken for epoch :  0.7971889615058899  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:36<00:00, 17.86it/s]
     Epoch Final   Train loss :  0.9990550216680728
     Epoch Final   Train dice :  0.1453387359538989
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:05<00:00, 26.85it/s]
     Epoch Final   validation loss :  0.9994348000735045
     Epoch Final   validation dice :  0.1683218809776008
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.65it/s]
     Epoch Final   testing loss :  0.9994611265647471
     Epoch Final   testing dice :  0.16938515585749897
Time taken for epoch :  0.8261445124944051  mins
Current Best epoch:  0
Total time to finish Training :  2.459152066707611  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_1/4/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_1/4
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_1/4/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_1/4/unet_best.bin
[ SUCCESS ] Total execution time: 0.91 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 43.83it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 46.18it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:15<00:00, 42.29it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.20it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.78it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:01:01
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:35<00:00, 17.93it/s]
     Epoch Final   Train loss :  0.9990292322209241
     Epoch Final   Train dice :  0.15226266618881773
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.78it/s]
     Epoch Final   validation loss :  0.999112944425263
     Epoch Final   validation dice :  0.16543947678545248
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.15it/s]
     Epoch Final   testing loss :  0.9991028421553806
     Epoch Final   testing dice :  0.16488794137292834
Time taken for epoch :  0.8262109200159709  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.79it/s]
     Epoch Final   Train loss :  0.9990442512936392
     Epoch Final   Train dice :  0.15249449317090064
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 26.91it/s]
     Epoch Final   validation loss :  0.9990612172191928
     Epoch Final   validation dice :  0.1581707262659665
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.14it/s]
     Epoch Final   testing loss :  0.9990553381431162
     Epoch Final   testing dice :  0.15771779551434872
Time taken for epoch :  0.7984086871147156  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.50it/s]
     Epoch Final   Train loss :  0.9990473915221717
     Epoch Final   Train dice :  0.14507911372842908
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.67it/s]
     Epoch Final   validation loss :  0.9990781867726249
     Epoch Final   validation dice :  0.13193125671111278
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.20it/s]
     Epoch Final   testing loss :  0.9990722347254777
     Epoch Final   testing dice :  0.1316237882595157
Time taken for epoch :  0.8414815227190654  mins
Current Best epoch:  1
Total time to finish Training :  2.484277606010437  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_2/0/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/0
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/0/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/0/unet_best.bin
[ SUCCESS ] Total execution time: 0.91 seconds. 
[ SUCCESS ] Memory consumed: 166 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 43.37it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 46.36it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:14<00:00, 42.95it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.01it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 45.77it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:04:27
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.77it/s]
     Epoch Final   Train loss :  0.9990330665701099
     Epoch Final   Train dice :  0.15222412756822343
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.36it/s]
     Epoch Final   validation loss :  0.9962519833019802
     Epoch Final   validation dice :  0.005630510934585927
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.03it/s]
     Epoch Final   testing loss :  0.995495199860625
     Epoch Final   testing dice :  0.005990930847878747
Time taken for epoch :  0.8342026114463806  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.80it/s]
     Epoch Final   Train loss :  0.9990425323995054
     Epoch Final   Train dice :  0.14934131741801837
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.77it/s]
     Epoch Final   validation loss :  0.9989575377162199
     Epoch Final   validation dice :  0.16776760681445554
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.61it/s]
     Epoch Final   testing loss :  0.9989716072580708
     Epoch Final   testing dice :  0.1672780460386134
Time taken for epoch :  0.7965087215105693  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.85it/s]
     Epoch Final   Train loss :  0.9990500782733757
     Epoch Final   Train dice :  0.14446698613522768
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 27.56it/s]
     Epoch Final   validation loss :  0.999065471361883
     Epoch Final   validation dice :  0.14148063453273002
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.53it/s]
     Epoch Final   testing loss :  0.9990713534070484
     Epoch Final   testing dice :  0.1411494717594996
Time taken for epoch :  0.8244010210037231  mins
Current Best epoch:  0
Total time to finish Training :  2.464372146129608  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_2/1/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/1
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/1/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/1/unet_best.bin
[ SUCCESS ] Total execution time: 0.89 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 44.08it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:14<00:00, 45.52it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:14<00:00, 43.41it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.20it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 47.02it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:07:51
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.83it/s]
     Epoch Final   Train loss :  0.9990321985485023
     Epoch Final   Train dice :  0.15152101574427973
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 26.89it/s]
     Epoch Final   validation loss :  0.9994646684723612
     Epoch Final   validation dice :  0.17003757437193615
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.65it/s]
     Epoch Final   testing loss :  0.9994598416546684
     Epoch Final   testing dice :  0.16892094658085363
Time taken for epoch :  0.826901892820994  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:33<00:00, 18.99it/s]
     Epoch Final   Train loss :  0.9990404031324905
     Epoch Final   Train dice :  0.1469913303249546
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 27.15it/s]
     Epoch Final   validation loss :  0.9990689602697859
     Epoch Final   validation dice :  0.15323603717806916
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.83it/s]
     Epoch Final   testing loss :  0.9990543906961508
     Epoch Final   testing dice :  0.15232077159395266
Time taken for epoch :  0.7882822195688883  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.59it/s]
     Epoch Final   Train loss :  0.9990312959506389
     Epoch Final   Train dice :  0.14524021796870565
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 26.95it/s]
     Epoch Final   validation loss :  0.9990809289564998
     Epoch Final   validation dice :  0.1393619449982732
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.18it/s]
     Epoch Final   testing loss :  0.9990662119874907
     Epoch Final   testing dice :  0.1386265302475412
Time taken for epoch :  0.8372278054555257  mins
Current Best epoch:  1
Total time to finish Training :  2.471445286273956  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_2/2/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/2
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/2/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/2/unet_best.bin
[ SUCCESS ] Total execution time: 0.90 seconds. 
[ SUCCESS ] Memory consumed: 166 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 45.23it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 47.33it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:14<00:00, 43.39it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 47.28it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 47.46it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:11:15
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:35<00:00, 17.88it/s]
     Epoch Final   Train loss :  0.9990399154496972
     Epoch Final   Train dice :  0.1529267141667903
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.02it/s]
     Epoch Final   validation loss :  0.9990266113547805
     Epoch Final   validation dice :  0.1590378644488613
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.82it/s]
     Epoch Final   testing loss :  0.9990306888053666
     Epoch Final   testing dice :  0.15873280501187736
Time taken for epoch :  0.8328232725461324  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.84it/s]
     Epoch Final   Train loss :  0.9990436130697212
     Epoch Final   Train dice :  0.14575864674746528
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.47it/s]
     Epoch Final   validation loss :  0.9988645167084214
     Epoch Final   validation dice :  0.16470026951398908
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.04it/s]
     Epoch Final   testing loss :  0.9988859820721755
     Epoch Final   testing dice :  0.16445242394855367
Time taken for epoch :  0.7992653330167134  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.61it/s]
     Epoch Final   Train loss :  0.9990429035612436
     Epoch Final   Train dice :  0.14525105270034233
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.22it/s]
     Epoch Final   validation loss :  0.9990947187317084
     Epoch Final   validation dice :  0.16686779140315441
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.86it/s]
     Epoch Final   testing loss :  0.9991003340156517
     Epoch Final   testing dice :  0.1666310140446051
Time taken for epoch :  0.840579076608022  mins
Current Best epoch:  1
Total time to finish Training :  2.49086350997289  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_2/3/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/3
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/3/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/3/unet_best.bin
[ SUCCESS ] Total execution time: 0.90 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 644/644 [00:14<00:00, 43.74it/s]
Calculating weights
Constructing queue for penalty data: 100% 644/644 [00:13<00:00, 46.28it/s]
Looping over training data for penalty calculation: 100% 644/644 [00:15<00:00, 42.00it/s]
Constructing queue for validation data: 100% 160/160 [00:03<00:00, 47.10it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.84it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:14:42
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:35<00:00, 17.92it/s]
     Epoch Final   Train loss :  0.9990419239175986
     Epoch Final   Train dice :  0.1527724618335133
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:05<00:00, 27.42it/s]
     Epoch Final   validation loss :  0.9990256987512112
     Epoch Final   validation dice :  0.1574452782049775
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.38it/s]
     Epoch Final   testing loss :  0.999052177910781
     Epoch Final   testing dice :  0.1578775712506688
Time taken for epoch :  0.8236347874005635  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:34<00:00, 18.79it/s]
     Epoch Final   Train loss :  0.9990481394603385
     Epoch Final   Train dice :  0.14894920681250393
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:05<00:00, 27.35it/s]
     Epoch Final   validation loss :  0.9990426354110241
     Epoch Final   validation dice :  0.14893484245985747
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.27it/s]
     Epoch Final   testing loss :  0.9990673426964983
     Epoch Final   testing dice :  0.149329917718522
Time taken for epoch :  0.7964492400487264  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:35<00:00, 17.90it/s]
     Epoch Final   Train loss :  0.9990485981569527
     Epoch Final   Train dice :  0.1426328985564272
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 26.11it/s]
     Epoch Final   validation loss :  0.9990412425249815
     Epoch Final   validation dice :  0.14049492161720992
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.05it/s]
     Epoch Final   testing loss :  0.9990661402246845
     Epoch Final   testing dice :  0.14083293302735286
Time taken for epoch :  0.8309433499972025  mins
Current Best epoch:  0
Total time to finish Training :  2.4598405798276266  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_2/4/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/4
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/4/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_2/4/unet_best.bin
[ SUCCESS ] Total execution time: 0.89 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 44.18it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:14<00:00, 45.63it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:14<00:00, 42.98it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.85it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.53it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:18:07
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.72it/s]
     Epoch Final   Train loss :  0.9990414277205757
     Epoch Final   Train dice :  0.1511963375410989
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.43it/s]
     Epoch Final   validation loss :  0.9992703117939256
     Epoch Final   validation dice :  0.16963155188175463
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.67it/s]
     Epoch Final   testing loss :  0.9992548239171801
     Epoch Final   testing dice :  0.16908399100920454
Time taken for epoch :  0.8374836961428325  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.50it/s]
     Epoch Final   Train loss :  0.9990438707694296
     Epoch Final   Train dice :  0.14917225678035667
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.47it/s]
     Epoch Final   validation loss :  0.9990730670668324
     Epoch Final   validation dice :  0.13858137913742422
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.57it/s]
     Epoch Final   testing loss :  0.9990480447289956
     Epoch Final   testing dice :  0.13824252480298133
Time taken for epoch :  0.8120939373970032  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.42it/s]
     Epoch Final   Train loss :  0.9990398049539949
     Epoch Final   Train dice :  0.14398874564916128
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 27.04it/s]
     Epoch Final   validation loss :  0.9990688040389778
     Epoch Final   validation dice :  0.14916888730866568
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.16it/s]
     Epoch Final   testing loss :  0.9990309838631853
     Epoch Final   testing dice :  0.14878378675055148
Time taken for epoch :  0.8430027445157369  mins
Current Best epoch:  2
Total time to finish Training :  2.5199663400650025  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_3/0/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/0
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/0/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/0/unet_best.bin
[ SUCCESS ] Total execution time: 1.01 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 45.38it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 46.17it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:15<00:00, 42.24it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.80it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.27it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:21:59
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.68it/s]
     Epoch Final   Train loss :  0.9990428458105535
     Epoch Final   Train dice :  0.15095531328655143
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 26.98it/s]
     Epoch Final   validation loss :  0.9994882219326422
     Epoch Final   validation dice :  0.15137403948891978
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.35it/s]
     Epoch Final   testing loss :  0.9995225730227001
     Epoch Final   testing dice :  0.15168996503697105
Time taken for epoch :  0.8329228401184082  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.63it/s]
     Epoch Final   Train loss :  0.9990507695203992
     Epoch Final   Train dice :  0.14542509832102254
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.53it/s]
     Epoch Final   validation loss :  0.9990627817485643
     Epoch Final   validation dice :  0.14056043627654544
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.37it/s]
     Epoch Final   testing loss :  0.9990499574153577
     Epoch Final   testing dice :  0.1401606345947702
Time taken for epoch :  0.8088322003682454  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.54it/s]
     Epoch Final   Train loss :  0.9990433458221459
     Epoch Final   Train dice :  0.14201448517120088
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 26.90it/s]
     Epoch Final   validation loss :  0.9990583284301047
     Epoch Final   validation dice :  0.14142716092907864
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.12it/s]
     Epoch Final   testing loss :  0.999045318928524
     Epoch Final   testing dice :  0.1410930157449115
Time taken for epoch :  0.8397712151209513  mins
Current Best epoch:  2
Total time to finish Training :  2.5077931602795918  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_3/1/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/1
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/1/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/1/unet_best.bin
[ SUCCESS ] Total execution time: 0.91 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 45.14it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:14<00:00, 45.84it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:15<00:00, 42.81it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.78it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.37it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:25:50
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.77it/s]
     Epoch Final   Train loss :  0.9990314278595184
     Epoch Final   Train dice :  0.1534241057619522
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.47it/s]
     Epoch Final   validation loss :  0.9990800911595362
     Epoch Final   validation dice :  0.14110614359378815
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.24it/s]
     Epoch Final   testing loss :  0.9990463820262928
     Epoch Final   testing dice :  0.14035273276603044
Time taken for epoch :  0.8324720541636149  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.60it/s]
     Epoch Final   Train loss :  0.9990510882152184
     Epoch Final   Train dice :  0.14716183460240786
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.62it/s]
     Epoch Final   validation loss :  0.9990860730964944
     Epoch Final   validation dice :  0.1319305977280836
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.30it/s]
     Epoch Final   testing loss :  0.999052261535208
     Epoch Final   testing dice :  0.13128319471629699
Time taken for epoch :  0.8046500126520792  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.73it/s]
     Epoch Final   Train loss :  0.9990317811305934
     Epoch Final   Train dice :  0.14377452540870403
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 27.08it/s]
     Epoch Final   validation loss :  0.9990797509317813
     Epoch Final   validation dice :  0.15162197412541195
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.28it/s]
     Epoch Final   testing loss :  0.9990464496375316
     Epoch Final   testing dice :  0.15073924745196726
Time taken for epoch :  0.8311345140139262  mins
Current Best epoch:  2
Total time to finish Training :  2.48575310309728  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_3/2/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/2
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/2/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/2/unet_best.bin
[ SUCCESS ] Total execution time: 0.91 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 45.74it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 46.17it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:15<00:00, 42.44it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.82it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.86it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:29:38
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.75it/s]
     Epoch Final   Train loss :  0.9990301500212163
     Epoch Final   Train dice :  0.15227384372827238
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.35it/s]
     Epoch Final   validation loss :  0.9980394299726308
     Epoch Final   validation dice :  0.12252620033780981
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.05it/s]
     Epoch Final   testing loss :  0.9984135443891459
     Epoch Final   testing dice :  0.12067312283895502
Time taken for epoch :  0.8346501469612122  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.65it/s]
     Epoch Final   Train loss :  0.9990472534952416
     Epoch Final   Train dice :  0.14940018007534658
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 27.01it/s]
     Epoch Final   validation loss :  0.9992392748038962
     Epoch Final   validation dice :  0.16931701345103128
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.98it/s]
     Epoch Final   testing loss :  0.999233107958267
     Epoch Final   testing dice :  0.1690666595501686
Time taken for epoch :  0.8031843264897665  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.71it/s]
     Epoch Final   Train loss :  0.9990442243185977
     Epoch Final   Train dice :  0.14475193104096928
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.61it/s]
     Epoch Final   validation loss :  0.9990546832913938
     Epoch Final   validation dice :  0.15150926988687574
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.48it/s]
     Epoch Final   testing loss :  0.999039016849366
     Epoch Final   testing dice :  0.15132320624085802
Time taken for epoch :  0.8377468069394429  mins
Current Best epoch:  0
Total time to finish Training :  2.484540851910909  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_3/3/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/3
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/3/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/3/unet_best.bin
[ SUCCESS ] Total execution time: 0.89 seconds. 
[ SUCCESS ] Memory consumed: 166 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 644/644 [00:14<00:00, 44.49it/s]
Calculating weights
Constructing queue for penalty data: 100% 644/644 [00:13<00:00, 46.73it/s]
Looping over training data for penalty calculation: 100% 644/644 [00:15<00:00, 42.85it/s]
Constructing queue for validation data: 100% 160/160 [00:03<00:00, 46.45it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 45.80it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:33:04
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:36<00:00, 17.66it/s]
     Epoch Final   Train loss :  0.9990610947705204
     Epoch Final   Train dice :  0.15420735415695988
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 26.61it/s]
     Epoch Final   validation loss :  0.9989447318017483
     Epoch Final   validation dice :  0.14145245859399438
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:08<00:00, 25.05it/s]
     Epoch Final   testing loss :  0.998948099601328
     Epoch Final   testing dice :  0.14176498509165067
Time taken for epoch :  0.84211132923762  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:34<00:00, 18.69it/s]
     Epoch Final   Train loss :  0.9990533258048644
     Epoch Final   Train dice :  0.14744677280093202
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:05<00:00, 26.72it/s]
     Epoch Final   validation loss :  0.9990116212517023
     Epoch Final   validation dice :  0.147314980532974
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.01it/s]
     Epoch Final   testing loss :  0.9990179322252226
     Epoch Final   testing dice :  0.14767017856759218
Time taken for epoch :  0.803258768717448  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:36<00:00, 17.60it/s]
     Epoch Final   Train loss :  0.9990544232152263
     Epoch Final   Train dice :  0.1456025161705217
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 26.48it/s]
     Epoch Final   validation loss :  0.9990375902503729
     Epoch Final   validation dice :  0.14677659049630165
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.22it/s]
     Epoch Final   testing loss :  0.9990431909537434
     Epoch Final   testing dice :  0.1471501881655176
Time taken for epoch :  0.8385746200879415  mins
Current Best epoch:  0
Total time to finish Training :  2.4935288310050963  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_3/4/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/4
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/4/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_3/4/unet_best.bin
[ SUCCESS ] Total execution time: 0.90 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 43.74it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 46.53it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:14<00:00, 42.89it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.83it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:07<00:00, 25.97it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:36:35
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.57it/s]
     Epoch Final   Train loss :  0.9990307266938371
     Epoch Final   Train dice :  0.15203946076831773
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.16it/s]
     Epoch Final   validation loss :  0.9991420877646215
     Epoch Final   validation dice :  0.15193805936145485
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.86it/s]
     Epoch Final   testing loss :  0.9991363779229311
     Epoch Final   testing dice :  0.1516947726631046
Time taken for epoch :  0.842666216691335  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.54it/s]
     Epoch Final   Train loss :  0.9990478406427066
     Epoch Final   Train dice :  0.14938515851137982
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.30it/s]
     Epoch Final   validation loss :  0.9990729189807583
     Epoch Final   validation dice :  0.13927190218653
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.06it/s]
     Epoch Final   testing loss :  0.999058346250164
     Epoch Final   testing dice :  0.13911392639822034
Time taken for epoch :  0.8089308182398478  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.45it/s]
     Epoch Final   Train loss :  0.999039715778772
     Epoch Final   Train dice :  0.1452748551385399
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 25.69it/s]
     Epoch Final   validation loss :  0.9991677825495323
     Epoch Final   validation dice :  0.1653261916792911
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.61it/s]
     Epoch Final   testing loss :  0.9991794216692151
     Epoch Final   testing dice :  0.1650565486790529
Time taken for epoch :  0.8495583375295003  mins
Current Best epoch:  1
Total time to finish Training :  2.520503803094228  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_4/0/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/0
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/0/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/0/unet_best.bin
[ SUCCESS ] Total execution time: 1.02 seconds. 
[ SUCCESS ] Memory consumed: 166 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 43.83it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 46.29it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:15<00:00, 42.55it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 47.24it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.91it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:40:03
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.69it/s]
     Epoch Final   Train loss :  0.9990379072459267
     Epoch Final   Train dice :  0.15151814181896428
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.39it/s]
     Epoch Final   validation loss :  0.9990765707833427
     Epoch Final   validation dice :  0.1372023772286332
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.92it/s]
     Epoch Final   testing loss :  0.9990720434568414
     Epoch Final   testing dice :  0.13707864458732938
Time taken for epoch :  0.8370583256085714  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.67it/s]
     Epoch Final   Train loss :  0.9990398995983841
     Epoch Final   Train dice :  0.14678770194806356
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.73it/s]
     Epoch Final   validation loss :  0.9990549102333022
     Epoch Final   validation dice :  0.14080414476787081
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.89it/s]
     Epoch Final   testing loss :  0.9990529847975395
     Epoch Final   testing dice :  0.14066470570083875
Time taken for epoch :  0.8040074865023296  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.51it/s]
     Epoch Final   Train loss :  0.999044099918235
     Epoch Final   Train dice :  0.1434247125386265
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.31it/s]
     Epoch Final   validation loss :  0.9990625440704156
     Epoch Final   validation dice :  0.15255186785452113
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.94it/s]
     Epoch Final   testing loss :  0.9990595181783041
     Epoch Final   testing dice :  0.15239705360350916
Time taken for epoch :  0.8436049222946167  mins
Current Best epoch:  1
Total time to finish Training :  2.5017507235209147  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_4/1/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/1
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/1/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/1/unet_best.bin
[ SUCCESS ] Total execution time: 1.07 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 44.33it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:14<00:00, 45.78it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:14<00:00, 42.88it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.73it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 47.14it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:43:30
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.65it/s]
     Epoch Final   Train loss :  0.9990319304666475
     Epoch Final   Train dice :  0.15140108927551363
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 25.71it/s]
     Epoch Final   validation loss :  0.9990740699797683
     Epoch Final   validation dice :  0.13964675542730723
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.66it/s]
     Epoch Final   testing loss :  0.9990502521766359
     Epoch Final   testing dice :  0.1390941565976807
Time taken for epoch :  0.842269492149353  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.54it/s]
     Epoch Final   Train loss :  0.9990336279476041
     Epoch Final   Train dice :  0.14836886203029478
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.29it/s]
     Epoch Final   validation loss :  0.9990824905241499
     Epoch Final   validation dice :  0.13432083339054393
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.69it/s]
     Epoch Final   testing loss :  0.9990587691169474
     Epoch Final   testing dice :  0.13381456075912684
Time taken for epoch :  0.810960062344869  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.70it/s]
     Epoch Final   Train loss :  0.9990485998371712
     Epoch Final   Train dice :  0.14361956203428805
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.12it/s]
     Epoch Final   validation loss :  0.999478020283006
     Epoch Final   validation dice :  0.1699540565102737
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.76it/s]
     Epoch Final   testing loss :  0.9994444666217216
     Epoch Final   testing dice :  0.16915904156011136
Time taken for epoch :  0.838559087117513  mins
Current Best epoch:  0
Total time to finish Training :  2.500284457206726  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_4/2/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/2
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/2/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/2/unet_best.bin
[ SUCCESS ] Total execution time: 0.89 seconds. 
[ SUCCESS ] Memory consumed: 166 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 643/643 [00:14<00:00, 43.14it/s]
Calculating weights
Constructing queue for penalty data: 100% 643/643 [00:13<00:00, 45.98it/s]
Looping over training data for penalty calculation: 100% 643/643 [00:15<00:00, 42.57it/s]
Constructing queue for validation data: 100% 161/161 [00:03<00:00, 46.11it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 46.46it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:46:57
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.53it/s]
     Epoch Final   Train loss :  0.9990342118506483
     Epoch Final   Train dice :  0.15094606008258984
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 27.06it/s]
     Epoch Final   validation loss :  0.9990521191810229
     Epoch Final   validation dice :  0.15588495107541173
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.26it/s]
     Epoch Final   testing loss :  0.9990497056524552
     Epoch Final   testing dice :  0.15589855848556727
Time taken for epoch :  0.8383732040723165  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:34<00:00, 18.56it/s]
     Epoch Final   Train loss :  0.999048784120272
     Epoch Final   Train dice :  0.14758447072183362
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:05<00:00, 26.85it/s]
     Epoch Final   validation loss :  0.9990633370713418
     Epoch Final   validation dice :  0.14831973566031603
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.21it/s]
     Epoch Final   testing loss :  0.9990591940595143
     Epoch Final   testing dice :  0.14835498496815933
Time taken for epoch :  0.8053333799044291  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 643/643 [00:36<00:00, 17.67it/s]
     Epoch Final   Train loss :  0.9990351461511378
     Epoch Final   Train dice :  0.14516869488622686
********************
Starting validation : 
********************
Looping over validation data: 100% 161/161 [00:06<00:00, 26.05it/s]
     Epoch Final   validation loss :  0.9990494366017928
     Epoch Final   validation dice :  0.15452883489753888
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.89it/s]
     Epoch Final   testing loss :  0.9990439079887238
     Epoch Final   testing dice :  0.15458225388432023
Time taken for epoch :  0.8389748573303223  mins
Current Best epoch:  2
Total time to finish Training :  2.5006306926409403  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_4/3/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/3
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/3/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/3/unet_best.bin
[ SUCCESS ] Total execution time: 1.23 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Number of channels :  1
Constructing queue for train data: 100% 644/644 [00:14<00:00, 45.01it/s]
Calculating weights
Constructing queue for penalty data: 100% 644/644 [00:13<00:00, 46.13it/s]
Looping over training data for penalty calculation: 100% 644/644 [00:14<00:00, 43.14it/s]
Constructing queue for validation data: 100% 160/160 [00:03<00:00, 47.02it/s]
Device requested via CUDA_VISIBLE_DEVICES:  0
Total number of CUDA devices:  1
Device finally used:  0
Sending model to aforementioned device
Memory Total :  14.8 GB, Allocated:  0.0 GB, Cached:  0.4 GB
Device - Current: 0 Count: 1 Name: Tesla T4 Availability: True
Constructing queue for testing data: 100% 201/201 [00:04<00:00, 47.27it/s]
Hostname : 8cbbe982617f
Initializing training at : 2022/05/28::21:50:48
Using device: cuda
********************
********************
Starting Epoch :  0
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:36<00:00, 17.60it/s]
     Epoch Final   Train loss :  0.9990393639721485
     Epoch Final   Train dice :  0.1517291944126905
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:05<00:00, 26.73it/s]
     Epoch Final   validation loss :  0.9990401402115822
     Epoch Final   validation dice :  0.15993852466344832
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 25.15it/s]
     Epoch Final   testing loss :  0.9990566891817311
     Epoch Final   testing dice :  0.1606709549379586
Time taken for epoch :  0.843364151318868  mins
Current Best epoch:  0
********************
********************
Starting Epoch :  1
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:34<00:00, 18.65it/s]
     Epoch Final   Train loss :  0.9990452579830004
     Epoch Final   Train dice :  0.14738571048014282
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 26.59it/s]
     Epoch Final   validation loss :  0.9990301836282015
     Epoch Final   validation dice :  0.15374664459377527
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.08it/s]
     Epoch Final   testing loss :  0.9990457993241685
     Epoch Final   testing dice :  0.1543901648687486
Time taken for epoch :  0.8044395009676616  mins
Current Best epoch:  1
********************
********************
Starting Epoch :  2
********************
Starting Training : 
********************
Looping over training data: 100% 644/644 [00:36<00:00, 17.46it/s]
     Epoch Final   Train loss :  0.9990614344429526
     Epoch Final   Train dice :  0.1441436953125348
********************
Starting validation : 
********************
Looping over validation data: 100% 160/160 [00:06<00:00, 25.41it/s]
     Epoch Final   validation loss :  0.9990420896559954
     Epoch Final   validation dice :  0.1401477782521397
********************
Starting testing : 
********************
Looping over testing data: 100% 201/201 [00:07<00:00, 26.28it/s]
     Epoch Final   testing loss :  0.9990580354756977
     Epoch Final   testing dice :  0.1406762584376691
Time taken for epoch :  0.8474669257799784  mins
Current Best epoch:  1
Total time to finish Training :  2.512435698509216  mins
Optimizing best model.
graph(%input : Float(1, 1, 128, 128, strides=[16384, 16384, 128, 1], requires_grad=0, device=cpu),
      %ins.conv2.weight : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=1, device=cpu),
      %ins.conv2.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %en_1.conv1.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %en_1.conv1.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %en_1.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_1.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %en_2.conv1.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %en_2.conv1.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %en_2.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_2.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %en_3.conv1.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %en_3.conv1.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %en_3.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_3.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %en_4.conv1.weight : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=1, device=cpu),
      %en_4.conv1.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %en_4.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %en_4.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_3.conv0.weight : Float(240, 480, 1, 1, strides=[480, 1, 1, 1], requires_grad=1, device=cpu),
      %us_3.conv0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.conv2.weight : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=1, device=cpu),
      %de_3.conv2.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.weight : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.bias : Float(480, strides=[1], requires_grad=1, device=cpu),
      %de_3.in_0.running_mean : Float(480, strides=[1], requires_grad=0, device=cpu),
      %de_3.in_0.running_var : Float(480, strides=[1], requires_grad=0, device=cpu),
      %us_2.conv0.weight : Float(120, 240, 1, 1, strides=[240, 1, 1, 1], requires_grad=1, device=cpu),
      %us_2.conv0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.conv2.weight : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=1, device=cpu),
      %de_2.conv2.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.weight : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.bias : Float(240, strides=[1], requires_grad=1, device=cpu),
      %de_2.in_0.running_mean : Float(240, strides=[1], requires_grad=0, device=cpu),
      %de_2.in_0.running_var : Float(240, strides=[1], requires_grad=0, device=cpu),
      %us_1.conv0.weight : Float(60, 120, 1, 1, strides=[120, 1, 1, 1], requires_grad=1, device=cpu),
      %us_1.conv0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.conv2.weight : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %de_1.conv2.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.weight : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.bias : Float(120, strides=[1], requires_grad=1, device=cpu),
      %de_1.in_0.running_mean : Float(120, strides=[1], requires_grad=0, device=cpu),
      %de_1.in_0.running_var : Float(120, strides=[1], requires_grad=0, device=cpu),
      %us_0.conv0.weight : Float(30, 60, 1, 1, strides=[60, 1, 1, 1], requires_grad=1, device=cpu),
      %us_0.conv0.bias : Float(30, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.weight : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.bias : Float(60, strides=[1], requires_grad=1, device=cpu),
      %de_0.in_0.running_mean : Float(60, strides=[1], requires_grad=0, device=cpu),
      %de_0.in_0.running_var : Float(60, strides=[1], requires_grad=0, device=cpu),
      %out.conv0.weight : Float(5, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=1, device=cpu),
      %out.conv0.bias : Float(5, strides=[1], requires_grad=1, device=cpu),
      %314 : Float(30, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),
      %315 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %317 : Float(30, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %318 : Float(30, strides=[1], requires_grad=0, device=cpu),
      %320 : Float(60, 30, 3, 3, strides=[270, 9, 3, 1], requires_grad=0, device=cpu),
      %321 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %323 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %324 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %326 : Float(120, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %327 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %329 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %330 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %332 : Float(240, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %333 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %335 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %336 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %338 : Float(480, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %339 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %341 : Float(480, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %342 : Float(480, strides=[1], requires_grad=0, device=cpu),
      %344 : Float(240, 480, 3, 3, strides=[4320, 9, 3, 1], requires_grad=0, device=cpu),
      %345 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %347 : Float(240, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %348 : Float(240, strides=[1], requires_grad=0, device=cpu),
      %350 : Float(120, 240, 3, 3, strides=[2160, 9, 3, 1], requires_grad=0, device=cpu),
      %351 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %353 : Float(120, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %354 : Float(120, strides=[1], requires_grad=0, device=cpu),
      %356 : Float(60, 120, 3, 3, strides=[1080, 9, 3, 1], requires_grad=0, device=cpu),
      %357 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %359 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %360 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %362 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %363 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %365 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %366 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %368 : Float(60, 60, 3, 3, strides=[540, 9, 3, 1], requires_grad=0, device=cpu),
      %369 : Float(60, strides=[1], requires_grad=0, device=cpu),
      %370 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %371 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %372 : Float(4, strides=[1], requires_grad=0, device=cpu),
      %373 : Float(4, strides=[1], requires_grad=0, device=cpu)):
  %313 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %314, %315)
  %202 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %316 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%202, %317, %318)
  %205 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %206 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%205, %ins.conv2.weight, %ins.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %319 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%206, %320, %321)
  %209 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%319) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %210 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%209, %en_1.in_0.weight, %en_1.in_0.bias, %en_1.in_0.running_mean, %en_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %211 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%210) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %322 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%211, %323, %324)
  %214 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%322) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %215 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%214, %en_1.conv1.weight, %en_1.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %325 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%215, %326, %327)
  %218 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%325) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %219 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%218, %en_2.in_0.weight, %en_2.in_0.bias, %en_2.in_0.running_mean, %en_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %220 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%219) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %328 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%220, %329, %330)
  %223 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%328) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %224 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%223, %en_2.conv1.weight, %en_2.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %331 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%224, %332, %333)
  %227 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %228 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%227, %en_3.in_0.weight, %en_3.in_0.bias, %en_3.in_0.running_mean, %en_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %229 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%228) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %334 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%229, %335, %336)
  %232 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%334) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %233 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%232, %en_3.conv1.weight, %en_3.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %337 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%233, %338, %339)
  %236 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%337) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %237 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%236, %en_4.in_0.weight, %en_4.in_0.bias, %en_4.in_0.running_mean, %en_4.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %238 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %340 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%238, %341, %342)
  %241 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%340) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %242 : Float(1, 480, 8, 8, strides=[30720, 64, 8, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%241, %en_4.conv1.weight, %en_4.conv1.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %246 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %247 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%242, %246, %370) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %248 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%247, %us_3.conv0.weight, %us_3.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %249 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%248, %233) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %250 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%249, %de_3.in_0.weight, %de_3.in_0.bias, %de_3.in_0.running_mean, %de_3.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %251 : Float(1, 480, 16, 16, strides=[122880, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%250) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %343 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%251, %344, %345)
  %254 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%343) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %346 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%254, %347, %348)
  %257 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%346) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %258 : Float(1, 240, 16, 16, strides=[61440, 256, 16, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%257, %de_3.conv2.weight, %de_3.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %262 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %263 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%258, %262, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %264 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%263, %us_2.conv0.weight, %us_2.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %265 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%264, %224) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %266 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%265, %de_2.in_0.weight, %de_2.in_0.bias, %de_2.in_0.running_mean, %de_2.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %267 : Float(1, 240, 32, 32, strides=[245760, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%266) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %349 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%267, %350, %351)
  %270 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%349) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %352 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%270, %353, %354)
  %273 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%352) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %274 : Float(1, 120, 32, 32, strides=[122880, 1024, 32, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%273, %de_2.conv2.weight, %de_2.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %278 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %279 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%274, %278, %372) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %280 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%279, %us_1.conv0.weight, %us_1.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %281 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%280, %215) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %282 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%281, %de_1.in_0.weight, %de_1.in_0.bias, %de_1.in_0.running_mean, %de_1.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %283 : Float(1, 120, 64, 64, strides=[491520, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%282) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %355 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%283, %356, %357)
  %286 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%355) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %358 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%286, %359, %360)
  %289 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%358) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %290 : Float(1, 60, 64, 64, strides=[245760, 4096, 64, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%289, %de_1.conv2.weight, %de_1.conv2.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %294 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ]]()
  %295 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode="align_corners", cubic_coeff_a=-0.75, mode="linear", nearest_mode="floor"](%290, %294, %373) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3554:0
  %296 : Float(1, 30, 128, 128, strides=[491520, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%295, %us_0.conv0.weight, %us_0.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %297 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%296, %206) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/DecodingModule.py:46:0
  %298 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%297, %de_0.in_0.weight, %de_0.in_0.bias, %de_0.in_0.running_mean, %de_0.in_0.running_var) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0
  %299 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%298) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %361 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%299, %362, %363)
  %302 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%361) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %364 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%302, %365, %366)
  %305 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%364) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %367 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%305, %368, %369)
  %308 : Float(1, 60, 128, 128, strides=[983040, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01](%367) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1376:0
  %309 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%308, %out.conv0.weight, %out.conv0.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0
  %310 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %311 : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%309, %310)
  %output : Float(1, 5, 128, 128, strides=[81920, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Sigmoid(%311) # /gdrive/MyDrive/GaNDLF/GANDLF/models/seg_modules/out_conv.py:56:0
  return (%output)

Model Optimizer arguments:
Common parameters:
	- Path to the Input Model: 	/gdrive/MyDrive/GaNDLF/./images_and_labels/model/testing_4/4/unet_best.onnx
	- Path for generated IR: 	/gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/4
	- IR output name: 	unet_best
	- Log level: 	ERROR
	- Batch: 	Not specified, inherited from the model
	- Input layers: 	Not specified, inherited from the model
	- Output layers: 	Not specified, inherited from the model
	- Input shapes: 	[1,1,128,128]
	- Source layout: 	Not specified
	- Target layout: 	Not specified
	- Layout: 	Not specified
	- Mean values: 	Not specified
	- Scale values: 	Not specified
	- Scale factor: 	Not specified
	- Precision of IR: 	FP32
	- Enable fusing: 	True
	- User transformations: 	Not specified
	- Reverse input channels: 	False
	- Enable IR generation for fixed input shape: 	False
	- Use the transformations config file: 	None
Advanced parameters:
	- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: 	False
	- Force the usage of new Frontend of Model Optimizer for model conversion into IR: 	False
OpenVINO runtime found in: 	/usr/local/lib/python3.7/dist-packages/openvino
OpenVINO runtime version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
Model Optimizer version: 	2022.1.0-7019-cdb9bec7210-releases/2022/1
[ WARNING ]  
Detected not satisfied dependencies:
	numpy: installed: 1.21.0, required: < 1.20

Please install required versions of components or run pip installation
pip install openvino-dev
[ SUCCESS ] Generated IR version 11 model.
[ SUCCESS ] XML file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/4/unet_best.xml
[ SUCCESS ] BIN file: /gdrive/MyDrive/GaNDLF/images_and_labels/model/testing_4/4/unet_best.bin
[ SUCCESS ] Total execution time: 0.94 seconds. 
[ SUCCESS ] Memory consumed: 165 MB. 
It's been a while, check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2022_bu_IOTG_OpenVINO-2022-1&content=upg_all&medium=organic or on the GitHub*
[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.
Find more information about API v2.0 and IR v11 at https://docs.openvino.ai
Finished.
